{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aquisition - Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "from __future__ import unicode_literals\n",
    "import tweepy\n",
    "import os\n",
    "import pandas as pd\n",
    "import unicodecsv as csv\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#vadersentiment vadersentimentintensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticating\n",
    "API_KEY = os.environ.get('API')\n",
    "API_SECRET = os.environ.get('API_secret_key')\n",
    "ACCESS_TOKEN = os.environ.get('Access_token')\n",
    "ACCESS_TOKEN_SECRET = os.environ.get('Access_token_secret')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets = tweepy.Cursor(api.user_timeline, screen_name=username, tweet_mode='extended').items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 1079906462753869824\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 1072095127894667264\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 1063987157650485248\n",
      "...799 tweets downloaded so far\n",
      "getting tweets before 1058388700617498624\n",
      "...999 tweets downloaded so far\n",
      "getting tweets before 1052529703800721407\n",
      "...1198 tweets downloaded so far\n",
      "getting tweets before 1045098909352235007\n",
      "...1396 tweets downloaded so far\n",
      "getting tweets before 1040214866450178048\n",
      "...1592 tweets downloaded so far\n",
      "getting tweets before 1034663158357655551\n",
      "...1792 tweets downloaded so far\n",
      "getting tweets before 1029022897787084799\n",
      "...1992 tweets downloaded so far\n",
      "getting tweets before 1022494827504644095\n",
      "...2192 tweets downloaded so far\n",
      "getting tweets before 1015947163292008450\n",
      "...2392 tweets downloaded so far\n",
      "getting tweets before 1009436321792786431\n",
      "...2592 tweets downloaded so far\n",
      "getting tweets before 1003024268756733951\n",
      "...2792 tweets downloaded so far\n",
      "getting tweets before 995424104286179327\n",
      "...2992 tweets downloaded so far\n",
      "getting tweets before 986294490074832895\n",
      "...3192 tweets downloaded so far\n",
      "getting tweets before 973920392543793153\n",
      "...3219 tweets downloaded so far\n",
      "getting tweets before 972542173030879232\n",
      "...3219 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    \n",
    "    #authorize api\n",
    "    auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #session.set('request_token', auth.request_token['oauth_token'])\n",
    "    #list for tweets\n",
    "    alltweets = []\n",
    "    \n",
    "    #make initial request for most recent tweets \n",
    "    new_tweets = api.user_timeline(screen_name = screen_name, count=200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(\"getting tweets before {}\".format(oldest))\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(\"...{} tweets downloaded so far\".format(len(alltweets)))\n",
    "        \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    \n",
    "    #write the csv\t\n",
    "    with open('%s_tweets.csv' % screen_name, 'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "        writer.writerows(outtweets)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #pass in the username of the account you want to download\n",
    "    get_all_tweets(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data saved to csv. See \"01B_Data_Cleaning_Twitter\" notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
