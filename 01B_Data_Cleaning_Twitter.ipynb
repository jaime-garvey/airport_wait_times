{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tweets_raw = pd.read_csv('data/trump_tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tweets = dt_tweets_raw.drop(['source', 'retweet_count', 'favorite_count', 'is_retweet', 'id_str'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tweets = dt_tweets.set_index('created_at')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-31c6d0eb367e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-31c6d0eb367e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_tweet' is not defined"
     ]
    }
   ],
   "source": [
    "dt_tweets['text'] = dt_tweets['text'].apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change date object to datetime\n",
    "dt_tweets['created_at'] = pd.to_datetime(dt_tweets['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-83f30c33908e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-83f30c33908e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create date column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdt_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "#create date column\n",
    "dt_tweets['date'] = [d.date() for d in dt_tweets['created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop created by column \n",
    "dt_tweets = dt_tweets.drop(['created_at'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change date object to datetime\n",
    "dt_tweets['date'] = pd.to_datetime(dt_tweets['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dates the index\n",
    "#dt_tweets = dt_tweets.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tweets.head(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment = dt_tweets['text'].apply(lambda x: analyzer.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tweets=pd.concat([dt_tweets,sentiment.apply(pd.Series)],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-23-2017 11:38:16</th>\n",
       "      <td>Busy week planned with a heavy focus on jobs and national security. Top executives coming in at 9:00 A.M. to talk manufacturing in America.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-24-2017 11:11:47</th>\n",
       "      <td>Will be meeting at 9:00 with top automobile executives concerning jobs in America. I want new plants to be built here for cars sold here!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-24-2017 16:58:06</th>\n",
       "      <td>A photo delivered yesterday that will be displayed in the upper/lower press hall. Thank you Abbas! https://t.co/Uzp0ivvRp0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-24-2017 17:04:01</th>\n",
       "      <td>Great meeting with automobile industry leaders at the @WhiteHouse this morning. Together we will #MAGA! https://t.co/OXdiLOkGsZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-24-2017 17:49:17</th>\n",
       "      <td>Signing orders to move forward with the construction of the Keystone XL and Dakota Access pipelines in the Oval Off… https://t.co/aOxmfO0vOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-25-2017 00:46:57</th>\n",
       "      <td>Great meeting with Ford CEO Mark Fields and General Motors CEO Mary Barra at the @WhiteHouse today. https://t.co/T0eIgO6LP8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-25-2017 02:16:19</th>\n",
       "      <td>Congratulations to @FoxNews for being number one in inauguration ratings. They were many times higher than FAKE NEWS @CNN - public is smart!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-25-2017 02:25:40</th>\n",
       "      <td>If Chicago doesn't fix the horrible \"carnage\" going on 228 shootings in 2017 with 42 killings (up 24% from 2016) I will send in the Feds!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-25-2017 02:37:48</th>\n",
       "      <td>Big day planned on NATIONAL SECURITY tomorrow. Among many other things we will build the wall!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-25-2017 12:10:01</th>\n",
       "      <td>I will be asking for a major investigation into VOTER FRAUD including those registered to vote in two states those who are illegal and....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                             text\n",
       "created_at                                                                                                                                                       \n",
       "01-23-2017 11:38:16  Busy week planned with a heavy focus on jobs and national security. Top executives coming in at 9:00 A.M. to talk manufacturing in America. \n",
       "01-24-2017 11:11:47  Will be meeting at 9:00 with top automobile executives concerning jobs in America. I want new plants to be built here for cars sold here!   \n",
       "01-24-2017 16:58:06  A photo delivered yesterday that will be displayed in the upper/lower press hall. Thank you Abbas! https://t.co/Uzp0ivvRp0                  \n",
       "01-24-2017 17:04:01  Great meeting with automobile industry leaders at the @WhiteHouse this morning. Together we will #MAGA! https://t.co/OXdiLOkGsZ             \n",
       "01-24-2017 17:49:17  Signing orders to move forward with the construction of the Keystone XL and Dakota Access pipelines in the Oval Off… https://t.co/aOxmfO0vOK\n",
       "01-25-2017 00:46:57  Great meeting with Ford CEO Mark Fields and General Motors CEO Mary Barra at the @WhiteHouse today. https://t.co/T0eIgO6LP8                 \n",
       "01-25-2017 02:16:19  Congratulations to @FoxNews for being number one in inauguration ratings. They were many times higher than FAKE NEWS @CNN - public is smart!\n",
       "01-25-2017 02:25:40  If Chicago doesn't fix the horrible \"carnage\" going on 228 shootings in 2017 with 42 killings (up 24% from 2016) I will send in the Feds!   \n",
       "01-25-2017 02:37:48  Big day planned on NATIONAL SECURITY tomorrow. Among many other things we will build the wall!                                              \n",
       "01-25-2017 12:10:01  I will be asking for a major investigation into VOTER FRAUD including those registered to vote in two states those who are illegal and....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorizing Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tweets['sentiment'] = np.where(dt_tweets['compound']<0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    4299\n",
       "1    1805\n",
       "dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tweets.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>RT By the time their fake news campaigns are fully exposed they ve already moved on to their next fake news campaign A g</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6100</th>\n",
       "      <td>Remember it was Buzzfeed that released the totally discredited Dossier paid for by Crooked Hillary Clinton and the Democrats as opposition research on which the entire Russian probe is based A very sad day for journalism but a great day for our Country</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6101</th>\n",
       "      <td>RT At what point in fairness after 2 years do Americans of good will say enough already If the SpecialCounsel had collusi</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>RT This is just the most egregious example of the rampant unfairness that has tainted this partisan witch hunt from the beg</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>Fake News is truly the ENEMY OF THE PEOPLE</td>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-0.6633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                              text  \\\n",
       "6099  RT By the time their fake news campaigns are fully exposed they ve already moved on to their next fake news campaign A g                                                                                                                                       \n",
       "6100  Remember it was Buzzfeed that released the totally discredited Dossier paid for by Crooked Hillary Clinton and the Democrats as opposition research on which the entire Russian probe is based A very sad day for journalism but a great day for our Country   \n",
       "6101  RT At what point in fairness after 2 years do Americans of good will say enough already If the SpecialCounsel had collusi                                                                                                                                      \n",
       "6102  RT This is just the most egregious example of the rampant unfairness that has tainted this partisan witch hunt from the beg                                                                                                                                    \n",
       "6103  Fake News is truly the ENEMY OF THE PEOPLE                                                                                                                                                                                                                     \n",
       "\n",
       "           date    neg    neu    pos  compound  sentiment  \n",
       "6099 2019-01-19  0.291  0.709  0.000 -0.7778    1          \n",
       "6100 2019-01-19  0.090  0.793  0.118  0.5199    0          \n",
       "6101 2019-01-19  0.000  0.873  0.127  0.4404    0          \n",
       "6102 2019-01-19  0.106  0.894  0.000 -0.3612    1          \n",
       "6103 2019-01-19  0.452  0.370  0.179 -0.6633    1          "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tweets.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe as pickle file\n",
    "\n",
    "with open('dt_tweets.pickle', 'wb') as to_write:\n",
    "    pickle.dump(dt_tweets, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
