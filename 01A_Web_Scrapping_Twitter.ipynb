{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aquisition - Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "chromedriver = \"/Applications/chromedriver\" \n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument(“ — incognito”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.trumptwitterarchive.com/archive\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_time = 0.7\n",
    "\n",
    "date_lst = []\n",
    "\n",
    "text_lst = []\n",
    "\n",
    "source_lst = []\n",
    "\n",
    "\n",
    "# find_elements_by_xpath returns an array of selenium objects.\n",
    "\n",
    "table = driver.find_elements_by_xpath(\"//*[@id=\"fixed\"]\")\n",
    "\n",
    "\n",
    "# use list comprehension to get the actual repo titles and not the selenium objects.\n",
    "titles = [x.text for x in titles_element]\n",
    "# print out all the titles.\n",
    "print('titles:')\n",
    "print(titles, '\\n')\n",
    "\n",
    "\n",
    "tweets_df = pd.DataFrame(colums = ['date', 'text', 'source'])\n",
    "\n",
    "table = driver.find_elements_by_xpath(\"//*[@id=\"fixed\"]\")\n",
    "\n",
    "items = driver.find_elements_by_xpath(//*[@id=\"fixed\"]/li[1])\n",
    "                                \n",
    "last xpath=  //*[@id=\"fixed\"]/li[6225]\n",
    "\n",
    "\n",
    "for date in dates:\n",
    "    date_lst.append(date)\n",
    "try:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    titles = WebDriverWait(driver, 5).until(EC.visibility_of_all_elements_located((By.XPATH, \"//div[@class='productDescriptionAndPrice']//h4/a\")))\n",
    "    for title in titles:\n",
    "    item_names.append(title.text)\n",
    "except:\n",
    "    pass\n",
    "for item_name in item_names:\n",
    "    print(item_name)\n",
    "driver.quit()\n",
    "\n",
    "                                \n",
    "date = driver.find_elements_by_xpath(//*[@id=\"fixed\"]/li[1]/span[1])\n",
    "                                #//*[@id=\"fixed\"]/li[2]/span[1]\n",
    "                                \n",
    "text = driver.find_elements_by_xpath(//*[@id=\"fixed\"]/li[1]/span[2]/span[1])\n",
    "                        #//*[@id=\"fixed\"]/li[2]/span[2]/span[1]\n",
    "                                \n",
    "source = driver.find_elements_by_xpath(//*[@id=\"fixed\"]/li[1]/span[2]/span[2])\n",
    "                                \n",
    "\n",
    " \n",
    "for i in table.find_elements_by_xpath('.//tr'):\n",
    "    print i.get_attribute('innerHTML')\n",
    "                                \n",
    "while True:\n",
    "    table = driver.find_elements_by_xpath(\"//*[@id=\"results\"]\")\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", rows[-1])\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "WebElement scroll = driver.findElement(By.id(\"someId\"));\n",
    "scroll.sendKeys(Keys.PAGE_DOWN);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data saved to csv. See \"01B_Data_Cleaning_Twitter\" notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
